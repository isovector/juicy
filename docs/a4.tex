\documentclass{article}
\usepackage{todonotes}
\usepackage{listings}
\usepackage[margin=0.5in]{geometry}

\title{CS 444 - A4}
\author{Jacob Abrahams - 20370104\\ Alexander Maguire - 20396195}

\lstdefinelanguage{scala}{
  morekeywords={abstract,case,catch,class,def,%
    do,else,extends,false,final,finally,%
    for,if,implicit,import,match,mixin,%
    new,null,object,override,package,%
    private,protected,requires,return,sealed,%
    super,this,throw,trait,true,try,%
    type,val,var,while,with,yield,Some,None,Option,Before,After,visit},
  otherkeywords={=>,<-,<\%,<:,>:,\#,@}, sensitive=true, morecomment=[l]{//}, morecomment=[n]{/*}{*/}, morestring=[b]",
  morestring=[b]', morestring=[b]""" }

\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

% Default settings for code listings
\lstset{frame=tb, language=scala, aboveskip=3mm, belowskip=3mm, showstringspaces=false, columns=flexible,
  basicstyle={\small\ttfamily}, numbers=none, numberstyle=\tiny\color{gray}, keywordstyle=\color{blue},
  commentstyle=\color{dkgreen}, stringstyle=\color{mauve}, frame=single, breaklines=true, breakatwhitespace=true
  tabsize=3 }

\begin{document}

\newcommand\type[1]{\texttt{#1}}
\newcommand\func[1]{\texttt{#1}}
\newcommand\code[1]{\texttt{#1}}
\renewcommand\value[1]{\texttt{#1}}
\newcommand\source[2]{See: \texttt{src/#1.scala}::\type{#2} \\}
\newcommand\testsrc[1]{See: \texttt{test/#1.scala} \\}

\maketitle


\section{Design}

\subsection{Resolver}
\subsubsection{Building the Package Tree}
The first step of the \type{Resolver} was to iterate over each compilation unit, and build a map from fully-qualified
typenames to their corresponding definitions. Additionally, at this step we created type definitions for primitives, and
injected them into the package tree.

The package tree provides several useful functions for working with types; for example, it allows us to get any types
which might reside in a given package (\code{import pkg.*} for example):
\begin{lstlisting}[language=Scala]
def getPackage(pkg: QName): Map[QName, TypeDefn] = {
  val len = pkg.length
  tree
    .filter(_._1.take(len) == pkg)  // same prefix
    .filter(_._1.length == len + 1) // directly inside
    .filter(_._2.isDefined)         // not a package
    .map { case (path, classDef) =>
      path.drop(len) -> classDef.get
    }
}
\end{lstlisting}
\source{ast/PackageTree}{PackageTree\#getPackage}

\subsubsection{Determining Type Scopes}
For each compilation unit (internally referred to as a \type{FileNode}), we constructed a ``type scope'' -- a map from a
single identifier to any types it might resolve to -- by pulling in references from the package tree. Type scopes are
written into the AST, so later stages can take advantage of this analysis.

\subsubsection{Resolving Types}
The \type{Resolver} then performs the actual type resolution of syntactically-available types. This is implemented via a
visitor over each \type{FileNode} whose purpose is to find every \type{Typename} existing in the AST and to point it
towards its definition from the package tree. Any \type{Typename} which fails to resolve unambiguously via the type
scope results in an error.



\subsection{Knower}
\subsubsection{Inheritance Expansion}
The \type{Knower} is responsible for hierarchy checking. The most interesting part of this pass is its flattening of
class hierarchies: every class pulls all of its parent's methods into scope, respecting hiding rules. This is
implemented via a lazy recursion over a class' resolved \code{extends}.

In order to get all classes deriving from \type{java.lang.Object}, the \type{Parser} was extended with a special case to
make any class without an explicit \code{extends} clause extend from \type{java.lang.Object}.

\begin{lstlisting}[language=Scala]
lazy val (inheritedMethods: Seq[MethodDefn], hidesMethods: Seq[MethodDefn]) = {
  val parentMethods =
    extnds
      .flatMap(
        _.resolved.get.inheritedMethods)
      .filter(!_.isCxr)
  val sigs =diff
    methods
      .map(_.signature)
  val (hides, keeps) =
    parentMethods
      .partition { parMeth =>
        sigs.contains(parMeth.signature)
      }

  (methods ++ keeps, hides)
}
\end{lstlisting}
\source{ast/AST}{TypeDefn}

\subsubsection{Interface Contract Verification}
Additionally, the \type{Knower} is responsible for determining whether classes satisfy their \code{implements}
contracts; similarly to the inheritance expansion stage, this is implemented by flattening the implementation hierarchy,
and ensuring every class has method signatures which agree with every interface in the hierarchy.

\source{resolver/HardlyKnower}{HardlyKnower\#apply:84}




\subsection{Scoper}
builds a scope table for every lexical scope
errors if things are defined multiple times in the same scope
notably doesn't determine what's in scope any given statement, which lead to some issues for analysis
but this approach was taken because it will simplify codegen's variable allocation
    refer to prober for implementation of this


\begin{lstlisting}[language=Scala]
node.visit { (self, context) =>
  self match {
    // ... other cases
    case Before(VarStmnt(name,_,tname,_)) =>
      if (curBlock != curClass && !curBlock.define(name, tname)) {
        // Already defined
        throw new ScopeError("Duplicate definition of variable \$name", self.from)
      }
    case Before(_: BlockStmnt) =>
      makeChildScope()
    case After(_: BlockStmnt) =>
      freeChildScope()
    case Before(_: WhileStmnt) =>
      makeChildScope()
    case After(_: WhileStmnt) =>
      freeChildScope()
  }
}
\end{lstlisting}
\source{scoper/Scoper}{Scoper\#apply}



\subsection{Disambiguator}
\subsubsection{Rewriter}
By the time we had the need to disambiguate names, we ran into an issue where our AST no longer provided semantic
information about what we were trying to accomplish. For example, static method calls would be represented in the AST
by:

\begin{lstlisting}[language=Scala]
val staticCall = parse("pkg.Type.method()")
staticCall === Call(Member(Member(Id("pkg"), Id("Type")), Id("method")))
\end{lstlisting}

Notably, this doesn't reflect that \code{pkg.Type} is not a member access, but instead refers to a single ontological
entity (the type \type{pkg.Type}). Any further passes over the AST would require re-implementing parsing this chained
member access into the intended type resolution. It was decided that instead we should rewrite the AST to elide this
issue.

Unfortunately, our generalized visitor strategy (described in \textit{A1}) turned out to have insufficient power to
implement AST rewriting. A brief review of the literature suggested a technique called \textit{Scrap Your Boilerplate}
(SYB), to implement this for arbitrary trees, however, the implementation details of this strategy were deemed to be
outside the scope of our project (plus, monads are scary).

Instead, we implemented a \func{rewrite} method on every node of the AST, who was responsibile for rewriting all of its
children, constructing a new version of itself (since our AST is mostly immutable), and then rewriting this new copy of
itself. An example of this pattern is shown here:

\begin{lstlisting}[language=Scala]
def rewrite(rule: Rewriter, context: Seq[Visitable]) = {
  val newContext = this +: context
  transfer(rule(
    IfStmnt(
      cond.rewrite(rule, newContext).asInstanceOf[Expression],
      then.rewrite(rule, newContext).asInstanceOf[BlockStmnt],
      otherwise.map(_.rewrite(rule, newContext).asInstanceOf[BlockStmnt])
    ), context))
}
\end{lstlisting}
\source{ast/AST}{IfStmnt\#rewrite}

\func{transfer} is a function which keeps metadata on the AST (for example, original source location and scope), while
\func{rule} is a partial function defined over AST nodes which returns what that node should be replaced with. To simply
visit the tree, the identity function will suffice as a \func{rule}. Unfortunately, this approach loses type-safety,
which isn't a huge issue in practice, but did make us squirm a little.


\subsubsection{Static Disambiguation}
With the \type{Rewriter} in place, it was now possible to rewrite chained member accesses representing qualified
types with static member accesses. Another pass of the AST is performed here to resolve all remaining types (those which
are not syntactically-available).

\begin{lstlisting}[language=Scala]
node.rewrite(Rewriter { (newNode: Visitable, context: Seq[Visitable]) =>
  implicit val implContext = context
  newNode match {
    // ... other cases
    case m: Member =>
      val folded =
        m.fold {
          case id: Id if id.status != SCOPE => Some(id)
          case _ => None
        }

      if (!folded.contains(None)) {
        val rhs = folded.flatten.last
        val path = folded.flatten.dropRight(1)
        val qname = path.map(_.name)

        if (path.last.status == TYPE) {
          val classDefn = node.resolve(qname, pkgtree, m.from).get

          // rewrite this member access with a static member access
          StaticMember(classDefn.asInstanceOf[ClassDefn], rhs)
        } else {
          disambiguate(rhs, qname)
          m
        }
      } else m
  }
}
\end{lstlisting}
\source{disambiguator/Disambiguator}{Disambiguator\#apply}



\subsection{Analysis Probe}
the analysis probe is responsible for checking field initialization order
also ensuring variables are in scope by the time they are used
    (since the scoper doesn't do this)
statement reachability
and method return
reachability is implemented by folding over the JLS rules for reachable and completing normally
since these turn out to be extraneous
    implemented as a tail-recursive walk over each lexical scope
    calling the next stmnt with whether or not it is reachable
        if this is ever false, we throw an error

\begin{lstlisting}[language=Scala]
private def probe(reachable: Boolean, stmnt: Statement): Boolean = {
  if (!reachable)
    throw UnreachableError(stmnt)

  stmnt match {
    case BlockStmnt(stmnts) =>
      (true /: stmnts)(probe)
    case IfStmnt(_, then, otherwise) =>
      if (otherwise.isDefined)
        probe(then) || probe(otherwise.get)
      else {
        probe(then)
        true
      }
    case WhileStmnt(cond, body) =>
      cond match {
        case BoolVal(true) => false
        case BoolVal(false) => probe(false, body)
        case _ => true
      }
    // ... other cases
\end{lstlisting}
\source{analysis/AnalysisProbe}{AnalysisProbe\#probe}



\subsection{Checker}
\subsubsection{Typechecking}
\subsubsection{Constant Folding}

\begin{lstlisting}[language=Scala]
\end{lstlisting}



\section{Challenges}
\begin{itemize}
    \item resolving is a bitch cause of spec
    \item resolved class equality infinitely looped
    \item rewriter
    \item technical debt for primitives and arrays
    \item scoper doesn't scope on a per-statement level
    \item checker should probably have been two passes
\end{itemize}




\section{Testing}

We've heavily depended on a strong testing infrastructure during the development of our code; at time of writing we have
a little over 70 unit tests. Because Scala has strong support for domain specific languages, scalatest is absolutely
lovely to use. Furthermore, the testing infrastructure is a first-class citizen, and so some of our later-stage tests
are capable of succinctly running A/B tests on code -- ensuring that text substitution changes the results from pass to
failure.

Our tests have been written from the bottom-up, marking very small units to be tested. Our philosophy has been
test-driven development, and on quite a few occasions this policy has prevented us from creating regression bugs.

An example of one of our parser tests looks like this:

\begin{lstlisting}[language=Scala]
"Parser" should "right-associate assignments" in {
  mkParser("a = b = 5").parseExpr() should be ===
    Assignment(
      Id("a"),
      Assignment(Id("b"), IntVal(5)))
}
\end{lstlisting}

\testsrc{*}

\end{document}

